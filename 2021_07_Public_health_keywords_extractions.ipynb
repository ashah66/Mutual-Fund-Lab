{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Steps:\n",
    "\n",
    "step 1: clean up columns by addressing abbreviations\n",
    "\n",
    "Step 2: create dataframe that contain all public health sentences\n",
    "\n",
    "Step 3: for each row, extract sentences that contain at least one keywords that belong to public health keyword lists for each sentences, put a new row into the dataframe, \n",
    "\n",
    "step 4: save the new pandas dataframe into excel file\n",
    "\n",
    "Step 5: repeat step 2, 3, and 4 for natural disaster keywords\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://github.com/ccirelli2/mutual_fund_analytics_lab_token_analysis/blob/73e08886ab681ac59903e43b62f7a06b549ba24f/notebooks/2020_01_keywords_sentences_extraction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (12,13,14,15,16,17,18,19,20,21,24,36,41,42) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "#data = pd.read_csv(r\"C:\\Users\\ysxia\\Dropbox\\Code\\MutualFund\\Data\\2021_07\\2021_07_MF_data_all_columns_year2010_2020_de_dup.csv\")\n",
    "data = pd.read_csv(r\"C:\\Users\\ysxia\\Dropbox\\Code\\MutualFund\\Data\\2021_07\\2021_07_MF_data_all_columns_year2010_2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164603, 49)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SEC_film_#</th>\n",
       "      <th>SEC_fund_file#</th>\n",
       "      <th>accession#</th>\n",
       "      <th>class_#</th>\n",
       "      <th>class_#_2</th>\n",
       "      <th>class_#_3</th>\n",
       "      <th>class_#_4</th>\n",
       "      <th>class_#_5</th>\n",
       "      <th>class_#_6</th>\n",
       "      <th>...</th>\n",
       "      <th>principal_risks</th>\n",
       "      <th>principal_strategies</th>\n",
       "      <th>risks_wc</th>\n",
       "      <th>sec_act</th>\n",
       "      <th>series_cik1</th>\n",
       "      <th>stock_series#</th>\n",
       "      <th>strategies_wc</th>\n",
       "      <th>total_word_counts</th>\n",
       "      <th>crsp_class</th>\n",
       "      <th>filing_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10638475.0</td>\n",
       "      <td>002-10758</td>\n",
       "      <td>0000004568-10-000004</td>\n",
       "      <td>c000023937</td>\n",
       "      <td>c000023938</td>\n",
       "      <td>c000023939</td>\n",
       "      <td>c000023940</td>\n",
       "      <td>c000023941</td>\n",
       "      <td>c000023942</td>\n",
       "      <td>...</td>\n",
       "      <td>you may lose money by investing in the fund. t...</td>\n",
       "      <td>the fund approaches the management of its inve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1933 act</td>\n",
       "      <td>s000008801</td>\n",
       "      <td>s000008801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50077</td>\n",
       "      <td>M</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SEC_film_# SEC_fund_file#            accession#     class_#  \\\n",
       "0           0  10638475.0      002-10758  0000004568-10-000004  c000023937   \n",
       "\n",
       "    class_#_2   class_#_3   class_#_4   class_#_5   class_#_6  ...  \\\n",
       "0  c000023938  c000023939  c000023940  c000023941  c000023942  ...   \n",
       "\n",
       "                                     principal_risks  \\\n",
       "0  you may lose money by investing in the fund. t...   \n",
       "\n",
       "                                principal_strategies risks_wc   sec_act  \\\n",
       "0  the fund approaches the management of its inve...      NaN  1933 act   \n",
       "\n",
       "  series_cik1 stock_series# strategies_wc total_word_counts crsp_class  \\\n",
       "0  s000008801    s000008801           NaN             50077          M   \n",
       "\n",
       "  filing_year  \n",
       "0        2010  \n",
       "\n",
       "[1 rows x 49 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017    17203\n",
       "2020    16737\n",
       "2016    16610\n",
       "2018    16357\n",
       "2015    16169\n",
       "2019    15540\n",
       "2013    15287\n",
       "2014    15052\n",
       "2012    13226\n",
       "2011    12933\n",
       "2010     9489\n",
       "Name: filing_year, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['filing_year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.dropna(subset=['principal_risks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017    17203\n",
       "2020    16737\n",
       "2016    16610\n",
       "2018    16357\n",
       "2015    16169\n",
       "2019    15540\n",
       "2013    15287\n",
       "2014    15052\n",
       "2012    13226\n",
       "2011    12933\n",
       "2010     9489\n",
       "Name: filing_year, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['filing_year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations = {'dr.': 'doctor', 'mr.': 'mister', 'bro.': 'brother', 'bro': 'brother', 'mrs.': 'mistress', 'ms.': 'miss', 'jr.': 'junior', 'sr.': 'senior',\n",
    "                 'e.g.': 'for example', 'vs.': 'versus', 'U.S.': 'United States','etc.': 'etcetera', 'J.P.': 'Justice of the Peace',\n",
    "                 'Inc.': 'Incorporated', 'LLC.': 'limited liability corporation', 'Co.': 'company', 'l.p.': 'limited partneship',\n",
    "                 'ltd.': 'limited', 'Jan.': 'January', 'Feb.': 'February', 'Mar.': 'March', 'Apr.': 'April', 'i.e.': 'for example',\n",
    "                 'Jun.': 'June', 'Jul.': 'July', 'Aug.': 'August', 'Oct.': 'October', 'Dec.': 'December', 'S.E.C.': 'SEC', 'Inv. Co. Act': 'Investment Company Act'}\n",
    "terminators = ['.', '!', '?']\n",
    "wrappers = ['\"', \"'\", ')', ']', '}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all(a_str, sub):\n",
    "    start = 0\n",
    "    while True:\n",
    "        start = a_str.find(sub, start)\n",
    "        if start == -1:\n",
    "            return\n",
    "        yield start\n",
    "        start += len(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentence_end(paragraph):\n",
    "    [possible_endings, contraction_locations] = [[], []]\n",
    "    contractions = abbreviations.keys()\n",
    "    sentence_terminators = terminators + [terminator + wrapper for wrapper in wrappers for terminator in terminators]\n",
    "    for sentence_terminator in sentence_terminators:\n",
    "        t_indices = list(find_all(paragraph, sentence_terminator))\n",
    "        possible_endings.extend(([] if not len(t_indices) else [[i, len(sentence_terminator)] for i in t_indices]))\n",
    "    for contraction in contractions:\n",
    "        c_indices = list(find_all(paragraph, contraction))\n",
    "        contraction_locations.extend(([] if not len(c_indices) else [i + len(contraction) for i in c_indices]))\n",
    "    possible_endings = [pe for pe in possible_endings if pe[0] + pe[1] not in contraction_locations]\n",
    "    if len(paragraph) in [pe[0] + pe[1] for pe in possible_endings]:\n",
    "        max_end_start = max([pe[0] for pe in possible_endings])\n",
    "        possible_endings = [pe for pe in possible_endings if pe[0] != max_end_start]\n",
    "    possible_endings = [pe[0] + pe[1] for pe in possible_endings if sum(pe) > len(paragraph) or (sum(pe) < len(paragraph) and paragraph[sum(pe)] == ' ')]\n",
    "    end = (-1 if not len(possible_endings) else max(possible_endings))\n",
    "    return end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentences(paragraph):\n",
    "    replacingList = [[\"?\", \"? \"], [\"!\", \"! \"],[\".\", \". \"],[\"(\", \" \"], [\")\", \" \"], [\",\", \" \"], [\"i. e.\", \"i.e\"], \n",
    "                     [\"e. g.\", \"e.g.\"],[\"U. S.\", \"U.S.\"], [\"J. P.\", \"J.P.\"], [\"l. p.\", \"l.p.\"], \n",
    "                     [\"S. E. C.\", \"S.E.C.\"]]\n",
    "    for items in replacingList:\n",
    "        paragraph = paragraph.replace(items[0], items[1])\n",
    "    paragraph = re.sub(' +', ' ', paragraph)\n",
    "    if paragraph != \"\":\n",
    "        if paragraph[0] == '?' or paragraph[0] == '.' or paragraph[0] == '!':\n",
    "            paragraph = paragraph[1:]\n",
    "    end = True\n",
    "    sentences = []\n",
    "    while end > -1:\n",
    "        end = find_sentence_end(paragraph)\n",
    "        if end > -1:\n",
    "            sentences.append(paragraph[end:].strip())\n",
    "            paragraph = paragraph[:end]\n",
    "    sentences.append(paragraph)\n",
    "    sentences.reverse()\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input paragraphs, then split into sentences by using the above function find_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing row:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing row:  5000\n",
      "processing row:  10000\n",
      "processing row:  15000\n",
      "processing row:  20000\n",
      "processing row:  25000\n",
      "processing row:  30000\n",
      "processing row:  35000\n",
      "processing row:  40000\n",
      "processing row:  45000\n",
      "processing row:  50000\n",
      "processing row:  55000\n",
      "processing row:  60000\n",
      "processing row:  65000\n",
      "processing row:  70000\n",
      "processing row:  75000\n",
      "processing row:  80000\n",
      "processing row:  85000\n",
      "processing row:  90000\n",
      "processing row:  95000\n",
      "processing row:  100000\n",
      "processing row:  105000\n",
      "processing row:  110000\n",
      "processing row:  115000\n",
      "processing row:  120000\n",
      "processing row:  125000\n",
      "processing row:  130000\n",
      "processing row:  135000\n",
      "processing row:  140000\n",
      "processing row:  145000\n",
      "processing row:  150000\n",
      "processing row:  155000\n",
      "processing row:  160000\n"
     ]
    }
   ],
   "source": [
    "data1['cleaned_principal_risks']= \"\"\n",
    "for row in range(len(data1)):\n",
    "    if row %5000 == 0:\n",
    "        print (\"processing row: \", row)\n",
    "    para = data1['principal_risks'].iloc[row]\n",
    "    sents = find_sentences(para)\n",
    "    data1['cleaned_principal_risks'].iloc[row] = sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164603, 50)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SEC_film_#</th>\n",
       "      <th>SEC_fund_file#</th>\n",
       "      <th>accession#</th>\n",
       "      <th>class_#</th>\n",
       "      <th>class_#_2</th>\n",
       "      <th>class_#_3</th>\n",
       "      <th>class_#_4</th>\n",
       "      <th>class_#_5</th>\n",
       "      <th>class_#_6</th>\n",
       "      <th>...</th>\n",
       "      <th>principal_strategies</th>\n",
       "      <th>risks_wc</th>\n",
       "      <th>sec_act</th>\n",
       "      <th>series_cik1</th>\n",
       "      <th>stock_series#</th>\n",
       "      <th>strategies_wc</th>\n",
       "      <th>total_word_counts</th>\n",
       "      <th>crsp_class</th>\n",
       "      <th>filing_year</th>\n",
       "      <th>cleaned_principal_risks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10638475.0</td>\n",
       "      <td>002-10758</td>\n",
       "      <td>0000004568-10-000004</td>\n",
       "      <td>c000023937</td>\n",
       "      <td>c000023938</td>\n",
       "      <td>c000023939</td>\n",
       "      <td>c000023940</td>\n",
       "      <td>c000023941</td>\n",
       "      <td>c000023942</td>\n",
       "      <td>...</td>\n",
       "      <td>the fund approaches the management of its inve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1933 act</td>\n",
       "      <td>s000008801</td>\n",
       "      <td>s000008801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50077</td>\n",
       "      <td>M</td>\n",
       "      <td>2010</td>\n",
       "      <td>[you may lose money by investing in the fund.,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SEC_film_# SEC_fund_file#            accession#     class_#  \\\n",
       "0           0  10638475.0      002-10758  0000004568-10-000004  c000023937   \n",
       "\n",
       "    class_#_2   class_#_3   class_#_4   class_#_5   class_#_6  ...  \\\n",
       "0  c000023938  c000023939  c000023940  c000023941  c000023942  ...   \n",
       "\n",
       "                                principal_strategies risks_wc   sec_act  \\\n",
       "0  the fund approaches the management of its inve...      NaN  1933 act   \n",
       "\n",
       "  series_cik1 stock_series# strategies_wc total_word_counts crsp_class  \\\n",
       "0  s000008801    s000008801           NaN             50077          M   \n",
       "\n",
       "  filing_year                            cleaned_principal_risks  \n",
       "0        2010  [you may lose money by investing in the fund.,...  \n",
       "\n",
       "[1 rows x 50 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data1['cleaned_principal_risks'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv('2021_07_principal_risks_cleaned_non_dedup.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Health Keywords to Search Sentences that Contain one or multiple of these keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Public Health keywords: \n",
    "ph_word = ['communicable diseases','health crises','pandemic','respiratory','illness','prevention','epidemic',\n",
    "           'coronavirus','health crisis','pandemics','sanitation','global health crises',\n",
    "           'covid','health screenings','pathogens','sars','global health crisis',\n",
    "           'covid 19','hiv','preparedness','sars cov 2','epidemics','disease','influenza',\n",
    "           'public health','virus','global health','diseases','mers','quarantines','h1n1','viruses']\n",
    "\n",
    "ph_word = [ 'communicable   diseases',         \n",
    "            'coronavirus',                          \n",
    "            'covid','covid 19',                     \n",
    "            'disease',                              \n",
    "            'epidemic',                             \n",
    "            'global health',                        \n",
    "            'global health crisis',                 \n",
    "            'health crises',                        \n",
    "            'health crisis' ,                       \n",
    "            'health screenings' ,                   \n",
    "            'hiv' ,                                 \n",
    "            'influenza', 'h1n1',                     \n",
    "            'pandemic','epidemic',             \n",
    "            'pathogens',                            \n",
    "            'prevention',                           \n",
    "            'public health',                        \n",
    "            'quarantines',                          \n",
    "            'respiratory illness',                  \n",
    "            'sanitation',                           \n",
    "            'sars', 'sars cov 2', 'mers',        \n",
    "            'virus']                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing row:  0\n",
      "processing row:  5000\n",
      "processing row:  10000\n",
      "processing row:  15000\n",
      "processing row:  20000\n",
      "processing row:  25000\n",
      "processing row:  30000\n",
      "processing row:  35000\n",
      "processing row:  40000\n",
      "processing row:  45000\n",
      "processing row:  50000\n",
      "processing row:  55000\n",
      "processing row:  60000\n",
      "processing row:  65000\n",
      "processing row:  70000\n",
      "processing row:  75000\n",
      "processing row:  80000\n",
      "processing row:  85000\n",
      "processing row:  90000\n",
      "processing row:  95000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import nltk.data\n",
    "import re\n",
    "#from nltk.tokenize import tokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters, PunktTrainer\n",
    "\n",
    "pubic_health = pd.DataFrame()\n",
    "ph_sents = []\n",
    "for row in range(len(data1)):\n",
    "    if row %5000 == 0:\n",
    "        print (\"processing row: \", row)\n",
    "    sentences = data1['cleaned_principal_risks'].iloc[row]\n",
    "    for i in range(len(sentences)):\n",
    "        for word in ph_word:\n",
    "            tokens = sentences[i].lower().split()\n",
    "            if word in tokens:\n",
    "                ph_sents.append([data1['accession#'].iloc[row],\n",
    "                                 data1['filing_year'].iloc[row],\n",
    "                                 data1['fund_name'].iloc[row],\n",
    "                                 sentences[i]])\n",
    "        \n",
    "        \n",
    "        #pubic_health = pubic_health.append({'accession#':data1['accession#'].iloc[row],\n",
    "        #                                    'filing_year':data1['filing_year'].iloc[row],\n",
    "        #                                    'fund_name':data1['fund_name'].iloc[row],                                                    \n",
    "        #                                    'sentences':sentences[i]},ignore_index=True)\n",
    "                                            #'sentences':re.sub(' +', ' ',\" \".join(sentences[i]).replace('\\n',' '))},ignore_index=True)\n",
    "pubic_health = pd.DataFrame(ph_sents, columns =['accession#',\n",
    "                                                'filing_year',\n",
    "                                                'fund_name', \n",
    "                                                'sentences'])               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11051, 4)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubic_health.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accession#</th>\n",
       "      <th>filing_year</th>\n",
       "      <th>fund_name</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000318478-20-000025</td>\n",
       "      <td>2020</td>\n",
       "      <td>bny mellon appreciation fund, inc.</td>\n",
       "      <td>&amp;nbsp; recent examples include pandemic risks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000318478-20-000025</td>\n",
       "      <td>2020</td>\n",
       "      <td>bny mellon appreciation fund, inc.</td>\n",
       "      <td>&amp;nbsp; recent examples include pandemic risks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000885409-20-000004</td>\n",
       "      <td>2020</td>\n",
       "      <td>dreyfus basic money market fund, inc</td>\n",
       "      <td>&amp;nbsp; recent examples include pandemic risks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000885409-20-000004</td>\n",
       "      <td>2020</td>\n",
       "      <td>dreyfus basic money market fund, inc</td>\n",
       "      <td>&amp;nbsp; recent examples include pandemic risks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000075176-20-000010</td>\n",
       "      <td>2020</td>\n",
       "      <td>bny mellon municipal bond fund</td>\n",
       "      <td>primarily in response to the covid-19 pandemic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             accession#  filing_year  \\\n",
       "0  0000318478-20-000025         2020   \n",
       "1  0000318478-20-000025         2020   \n",
       "2  0000885409-20-000004         2020   \n",
       "3  0000885409-20-000004         2020   \n",
       "4  0000075176-20-000010         2020   \n",
       "\n",
       "                                  fund_name  \\\n",
       "0    bny mellon appreciation fund, inc.       \n",
       "1    bny mellon appreciation fund, inc.       \n",
       "2  dreyfus basic money market fund, inc       \n",
       "3  dreyfus basic money market fund, inc       \n",
       "4        bny mellon municipal bond fund       \n",
       "\n",
       "                                           sentences  \n",
       "0  &nbsp; recent examples include pandemic risks ...  \n",
       "1  &nbsp; recent examples include pandemic risks ...  \n",
       "2  &nbsp; recent examples include pandemic risks ...  \n",
       "3  &nbsp; recent examples include pandemic risks ...  \n",
       "4  primarily in response to the covid-19 pandemic...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubic_health.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    9109\n",
       "2017     297\n",
       "2018     278\n",
       "2016     268\n",
       "2015     247\n",
       "2019     242\n",
       "2014     180\n",
       "2013     132\n",
       "2012     130\n",
       "2011     112\n",
       "2010      56\n",
       "Name: filing_year, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubic_health['filing_year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubic_health.to_excel(\"2021_07_public_health_keywords_sentences_dedup.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    " nd_word = [ 'cyclones',                   \n",
    "             'death',                      \n",
    "             'drought',                    \n",
    "             'earthquakes',                \n",
    "             'environmental damage',       \n",
    "             'cloud',                      \n",
    "             'disaster',                   \n",
    "             'droughts',                   \n",
    "             'earthquake',                 \n",
    "             'fire',                       \n",
    "             'flood',                      \n",
    "             'hurricane',                  \n",
    "             'hurricanes',                 \n",
    "             'lightning',                  \n",
    "             'natural disaster',           \n",
    "             'natural disasters',          \n",
    "             'seismic',                    \n",
    "             'storms',                     \n",
    "             'tornadoes',                  \n",
    "             'tsunami',                    \n",
    "             'underground',                \n",
    "             'volcanoes',                  \n",
    "             'windstorms']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing row:  0\n",
      "processing row:  5000\n",
      "processing row:  10000\n",
      "processing row:  15000\n",
      "processing row:  20000\n",
      "processing row:  25000\n",
      "processing row:  30000\n",
      "processing row:  35000\n",
      "processing row:  40000\n",
      "processing row:  45000\n",
      "processing row:  50000\n",
      "processing row:  55000\n",
      "processing row:  60000\n",
      "processing row:  65000\n",
      "processing row:  70000\n",
      "processing row:  75000\n",
      "processing row:  80000\n",
      "processing row:  85000\n",
      "processing row:  90000\n",
      "processing row:  95000\n"
     ]
    }
   ],
   "source": [
    "nd_sents = []\n",
    "for row in range(len(data1)):\n",
    "    if row %5000 == 0:\n",
    "        print (\"processing row: \", row)\n",
    "    sentences = data1['cleaned_principal_risks'].iloc[row]\n",
    "    for i in range(len(sentences)):\n",
    "        for word in nd_word:\n",
    "            tokens = sentences[i].lower().split()\n",
    "            if word in tokens:\n",
    "                nd_sents.append([data1['accession#'].iloc[row],\n",
    "                                 data1['filing_year'].iloc[row],\n",
    "                                 data1['fund_name'].iloc[row],\n",
    "                                 sentences[i]])\n",
    "        \n",
    "        \n",
    "        #pubic_health = pubic_health.append({'accession#':data1['accession#'].iloc[row],\n",
    "        #                                    'filing_year':data1['filing_year'].iloc[row],\n",
    "        #                                    'fund_name':data1['fund_name'].iloc[row],                                                    \n",
    "        #                                    'sentences':sentences[i]},ignore_index=True)\n",
    "                                            #'sentences':re.sub(' +', ' ',\" \".join(sentences[i]).replace('\\n',' '))},ignore_index=True)\n",
    "natural_disaster = pd.DataFrame(nd_sents, columns =['accession#',\n",
    "                                                'filing_year',\n",
    "                                                'fund_name', \n",
    "                                                'sentences'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8897, 4)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natural_disaster.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    2138\n",
       "2019    1075\n",
       "2018    1047\n",
       "2017     949\n",
       "2016     863\n",
       "2015     808\n",
       "2014     598\n",
       "2013     519\n",
       "2012     453\n",
       "2011     303\n",
       "2010     144\n",
       "Name: filing_year, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natural_disaster['filing_year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_disaster.to_excel(\"2021_07_natural_disaster_keywords_sentences_dedup.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubic_health_non_dedup = pd.read_excel('2021_07_public_health_keywords_sentences.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>accession#</th>\n",
       "      <th>filing_year</th>\n",
       "      <th>fund_name</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000067590-10-000940</td>\n",
       "      <td>2010</td>\n",
       "      <td>prudential real assets fund</td>\n",
       "      <td>prices of commodities and related contracts ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0000088053-10-000446</td>\n",
       "      <td>2010</td>\n",
       "      <td>dws enhanced commodity strategy fund</td>\n",
       "      <td>the value of commodity-linked derivative instr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            accession#  filing_year  \\\n",
       "0           0  0000067590-10-000940         2010   \n",
       "1           1  0000088053-10-000446         2010   \n",
       "\n",
       "                              fund_name  \\\n",
       "0           prudential real assets fund   \n",
       "1  dws enhanced commodity strategy fund   \n",
       "\n",
       "                                           sentences  \n",
       "0  prices of commodities and related contracts ma...  \n",
       "1  the value of commodity-linked derivative instr...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubic_health_non_dedup.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    14045\n",
       "2017      624\n",
       "2016      524\n",
       "2018      464\n",
       "2015      425\n",
       "2019      393\n",
       "2014      289\n",
       "2012      239\n",
       "2013      239\n",
       "2011      192\n",
       "2010      102\n",
       "Name: filing_year, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubic_health_non_dedup['filing_year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
