{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55345904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49488179",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"2022_01_22_MF_all_year_data_without_duplicates_drop142_new.csv\", encoding = 'latin1', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45203062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112599, 699)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f24a2622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'accession#', 'filing_date', 'fund_name', 'fund_CIK',\n",
       "       'stock_series#', 'principal_risks', 'principal_strategies',\n",
       "       'business_address', 'mail_address',\n",
       "       ...\n",
       "       'Unnamed: 689', 'Unnamed: 690', 'Unnamed: 691', 'Unnamed: 692',\n",
       "       'Unnamed: 693', 'Unnamed: 694', 'Unnamed: 695', 'Unnamed: 696',\n",
       "       'Unnamed: 697', 'Unnamed: 698'],\n",
       "      dtype='object', length=699)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb235260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'accession#', 'filing_date', 'fund_name', 'fund_CIK',\n",
       "       'stock_series#', 'principal_risks', 'principal_strategies',\n",
       "       'business_address', 'mail_address', 'crsp_obj', 'crsp_class',\n",
       "       'filing_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = data.iloc[:,0:13]\n",
    "data1 = data1[pd.to_numeric(data1['Unnamed: 0'], errors='coerce').notnull()]\n",
    "data1 = data1[pd.to_numeric(data1['filing_date'], errors='coerce').notnull()]\n",
    "data1 = data1[pd.to_numeric(data1['fund_CIK'], errors='coerce').notnull()]\n",
    "data1 = data1[pd.to_numeric(data1['filing_year'], errors='coerce').notnull()]\n",
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9207b829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105514, 13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27b932eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    10164\n",
       "2019    10031\n",
       "2018     9938\n",
       "2017     9793\n",
       "2016     9657\n",
       "2015     9345\n",
       "2014     8917\n",
       "2021     8774\n",
       "2013     8467\n",
       "2012     7809\n",
       "2011     7168\n",
       "2010     5451\n",
       "Name: filing_year, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['filing_year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e8796f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv('2022_01_22_MF_all_year_data_without_duplicates_drop142_cleaned.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee49ffab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1.dropna(subset=['principal_risks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab20c5c0",
   "metadata": {},
   "source": [
    "### Extract Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cbbbb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations = {'dr.': 'doctor', 'mr.': 'mister', 'bro.': 'brother', 'bro': 'brother', 'mrs.': 'mistress', 'ms.': 'miss', 'jr.': 'junior', 'sr.': 'senior',\n",
    "                 'e.g.': 'for example', 'vs.': 'versus', 'U.S.': 'United States','etc.': 'etcetera', 'J.P.': 'Justice of the Peace',\n",
    "                 'Inc.': 'Incorporated', 'LLC.': 'limited liability corporation', 'Co.': 'company', 'l.p.': 'limited partneship',\n",
    "                 'ltd.': 'limited', 'Jan.': 'January', 'Feb.': 'February', 'Mar.': 'March', 'Apr.': 'April', 'i.e.': 'for example',\n",
    "                 'Jun.': 'June', 'Jul.': 'July', 'Aug.': 'August', 'Oct.': 'October', 'Dec.': 'December', 'S.E.C.': 'SEC', 'Inv. Co. Act': 'Investment Company Act'}\n",
    "terminators = ['.', '!', '?']\n",
    "wrappers = ['\"', \"'\", ')', ']', '}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b4b79e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all(a_str, sub):\n",
    "    start = 0\n",
    "    while True:\n",
    "        start = a_str.find(sub, start)\n",
    "        if start == -1:\n",
    "            return\n",
    "        yield start\n",
    "        start += len(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae2b6786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentence_end(paragraph):\n",
    "    [possible_endings, contraction_locations] = [[], []]\n",
    "    contractions = abbreviations.keys()\n",
    "    sentence_terminators = terminators + [terminator + wrapper for wrapper in wrappers for terminator in terminators]\n",
    "    for sentence_terminator in sentence_terminators:\n",
    "        t_indices = list(find_all(paragraph, sentence_terminator))\n",
    "        possible_endings.extend(([] if not len(t_indices) else [[i, len(sentence_terminator)] for i in t_indices]))\n",
    "    for contraction in contractions:\n",
    "        c_indices = list(find_all(paragraph, contraction))\n",
    "        contraction_locations.extend(([] if not len(c_indices) else [i + len(contraction) for i in c_indices]))\n",
    "    possible_endings = [pe for pe in possible_endings if pe[0] + pe[1] not in contraction_locations]\n",
    "    if len(paragraph) in [pe[0] + pe[1] for pe in possible_endings]:\n",
    "        max_end_start = max([pe[0] for pe in possible_endings])\n",
    "        possible_endings = [pe for pe in possible_endings if pe[0] != max_end_start]\n",
    "    possible_endings = [pe[0] + pe[1] for pe in possible_endings if sum(pe) > len(paragraph) or (sum(pe) < len(paragraph) and paragraph[sum(pe)] == ' ')]\n",
    "    end = (-1 if not len(possible_endings) else max(possible_endings))\n",
    "    return end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84250be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentences(paragraph):\n",
    "    replacingList = [[\"?\", \"? \"], [\"!\", \"! \"],[\".\", \". \"],[\"(\", \" \"], [\")\", \" \"], [\",\", \" \"], [\"i. e.\", \"i.e\"], \n",
    "                     [\"e. g.\", \"e.g.\"],[\"U. S.\", \"U.S.\"], [\"J. P.\", \"J.P.\"], [\"l. p.\", \"l.p.\"], \n",
    "                     [\"S. E. C.\", \"S.E.C.\"]]\n",
    "    for items in replacingList:\n",
    "        paragraph = paragraph.replace(items[0], items[1])\n",
    "    paragraph = re.sub(' +', ' ', paragraph)\n",
    "    if paragraph != \"\":\n",
    "        if paragraph[0] == '?' or paragraph[0] == '.' or paragraph[0] == '!':\n",
    "            paragraph = paragraph[1:]\n",
    "    end = True\n",
    "    sentences = []\n",
    "    while end > -1:\n",
    "        end = find_sentence_end(paragraph)\n",
    "        if end > -1:\n",
    "            sentences.append(paragraph[end:].strip())\n",
    "            paragraph = paragraph[:end]\n",
    "    sentences.append(paragraph)\n",
    "    sentences.reverse()\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc43f90",
   "metadata": {},
   "source": [
    "### input paragraphs, then split into sentences by using the above function find_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91f35e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing row:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshay\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing row:  5000\n",
      "processing row:  10000\n",
      "processing row:  15000\n",
      "processing row:  20000\n",
      "processing row:  25000\n",
      "processing row:  30000\n",
      "processing row:  35000\n",
      "processing row:  40000\n",
      "processing row:  45000\n",
      "processing row:  50000\n",
      "processing row:  55000\n",
      "processing row:  60000\n",
      "processing row:  65000\n",
      "processing row:  70000\n",
      "processing row:  75000\n",
      "processing row:  80000\n",
      "processing row:  85000\n",
      "processing row:  90000\n",
      "processing row:  95000\n",
      "processing row:  100000\n",
      "processing row:  105000\n",
      "processing row:  110000\n"
     ]
    }
   ],
   "source": [
    "data1['cleaned_principal_risks']= \"\"\n",
    "for row in range(len(data1)):\n",
    "    if row %5000 == 0:\n",
    "        print (\"processing row: \", row)\n",
    "    para = data1['principal_risks'].iloc[row]\n",
    "    sents = find_sentences(para)\n",
    "    data1['cleaned_principal_risks'].iloc[row] = sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90920256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111367, 700)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e50b24f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>accession#</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>fund_name</th>\n",
       "      <th>fund_CIK</th>\n",
       "      <th>stock_series#</th>\n",
       "      <th>principal_risks</th>\n",
       "      <th>principal_strategies</th>\n",
       "      <th>business_address</th>\n",
       "      <th>mail_address</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 690</th>\n",
       "      <th>Unnamed: 691</th>\n",
       "      <th>Unnamed: 692</th>\n",
       "      <th>Unnamed: 693</th>\n",
       "      <th>Unnamed: 694</th>\n",
       "      <th>Unnamed: 695</th>\n",
       "      <th>Unnamed: 696</th>\n",
       "      <th>Unnamed: 697</th>\n",
       "      <th>Unnamed: 698</th>\n",
       "      <th>cleaned_principal_risks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57167</td>\n",
       "      <td>0001104659-10-000128</td>\n",
       "      <td>20100104</td>\n",
       "      <td>ssga core edge equity fund</td>\n",
       "      <td>826686</td>\n",
       "      <td>s000018548</td>\n",
       "      <td>it is possible to lose money by investing in t...</td>\n",
       "      <td>ssga core edge equity fund invests at least 80...</td>\n",
       "      <td>STREET 1: 909 A ST CITY: TACOMA STATE: WA ZIP...</td>\n",
       "      <td>STREET 1: 909 A STREET CITY: TACOMA STATE: WA...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[it is possible to lose money by investing in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 700 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0            accession# filing_date                   fund_name  \\\n",
       "0      57167  0001104659-10-000128    20100104  ssga core edge equity fund   \n",
       "\n",
       "  fund_CIK stock_series#                                    principal_risks  \\\n",
       "0   826686    s000018548  it is possible to lose money by investing in t...   \n",
       "\n",
       "                                principal_strategies  \\\n",
       "0  ssga core edge equity fund invests at least 80...   \n",
       "\n",
       "                                    business_address  \\\n",
       "0   STREET 1: 909 A ST CITY: TACOMA STATE: WA ZIP...   \n",
       "\n",
       "                                        mail_address  ... Unnamed: 690  \\\n",
       "0   STREET 1: 909 A STREET CITY: TACOMA STATE: WA...  ...          NaN   \n",
       "\n",
       "  Unnamed: 691 Unnamed: 692 Unnamed: 693 Unnamed: 694 Unnamed: 695  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "  Unnamed: 696 Unnamed: 697 Unnamed: 698  \\\n",
       "0          NaN          NaN          NaN   \n",
       "\n",
       "                             cleaned_principal_risks  \n",
       "0  [it is possible to lose money by investing in ...  \n",
       "\n",
       "[1 rows x 700 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4656aed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data1['cleaned_principal_risks'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f16c619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv('2022_01_22_principal_risks_cleaned_non_dedup_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc5346e",
   "metadata": {},
   "source": [
    "### Public Health Keywords to Search Sentences that Contain one or multiple of these keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "841c324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Public Health keywords: \n",
    "ph_word = ['communicable diseases','health crises','pandemic','respiratory','illness','prevention','epidemic',\n",
    "           'coronavirus','health crisis','pandemics','sanitation','global health crises',\n",
    "           'covid','health screenings','pathogens','sars','global health crisis',\n",
    "           'covid 19','hiv','preparedness','sars cov 2','epidemics','disease','influenza',\n",
    "           'public health','virus','global health','diseases','mers','quarantines','h1n1','viruses']\n",
    "\n",
    "ph_word = [ 'communicable   diseases',         \n",
    "            'coronavirus',                          \n",
    "            'covid','covid 19',                     \n",
    "            'disease',                              \n",
    "            'epidemic',                             \n",
    "            'global health',                        \n",
    "            'global health crisis',                 \n",
    "            'health crises',                        \n",
    "            'health crisis' ,                       \n",
    "            'health screenings' ,                   \n",
    "            'hiv' ,                                 \n",
    "            'influenza', 'h1n1',                     \n",
    "            'pandemic','epidemic',             \n",
    "            'pathogens',                            \n",
    "            'prevention',                           \n",
    "            'public health',                        \n",
    "            'quarantines',                          \n",
    "            'respiratory illness',                  \n",
    "            'sanitation',                           \n",
    "            'sars', 'sars cov 2', 'mers',        \n",
    "            'virus']\n",
    "\n",
    "ph_word = [ 'communicable diseases',\n",
    "            'coronavirus',\n",
    "            'covid','covid 19',\n",
    "            'disease',\n",
    "            'epidemic',\n",
    "            'global health',\n",
    "            'global health crisis',\n",
    "            'health crises',\n",
    "            'health crisis' ,\n",
    "            'health screenings' ,\n",
    "            'hiv' ,\n",
    "            'influenza', 'h1n1',\n",
    "            'pandemic','epidemic',\n",
    "            'pathogens',\n",
    "            'prevention',\n",
    "            'public health',\n",
    "            'quarantines',\n",
    "            'respiratory illness',\n",
    "            'sanitation',\n",
    "            'sars', 'sars cov 2', 'mers',\n",
    "            'virus','COVID','COVID-','COVID –','Virus','Outbreak','Global pandemic','Vaccine','Delta','Omicron','Variant','Lockdown','closure /s COVID',\n",
    "            'case count /s COVID','case /s COVID','epidemic','endemic',\n",
    "            'death toll /s COVID',\n",
    "            'infectious disease risk',\n",
    "            'coronavirus',\n",
    "            'economic disruption /s COVID',\n",
    "            'vaccine hesitancy',\n",
    "            'vaccine skepticism',\n",
    "            'vaccine opposition',\n",
    "            'vaccine rollout',\n",
    "            'vaccine mandate',\n",
    "            'vaccine passport',\n",
    "            'novel virus',\n",
    "            'COVID measures' ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3d889db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing row:  0\n",
      "processing row:  5000\n",
      "processing row:  10000\n",
      "processing row:  15000\n",
      "processing row:  20000\n",
      "processing row:  25000\n",
      "processing row:  30000\n",
      "processing row:  35000\n",
      "processing row:  40000\n",
      "processing row:  45000\n",
      "processing row:  50000\n",
      "processing row:  55000\n",
      "processing row:  60000\n",
      "processing row:  65000\n",
      "processing row:  70000\n",
      "processing row:  75000\n",
      "processing row:  80000\n",
      "processing row:  85000\n",
      "processing row:  90000\n",
      "processing row:  95000\n",
      "processing row:  100000\n",
      "processing row:  105000\n",
      "processing row:  110000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import nltk.data\n",
    "import re\n",
    "#from nltk.tokenize import tokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters, PunktTrainer\n",
    "\n",
    "pubic_health = pd.DataFrame()\n",
    "ph_sents = []\n",
    "for row in range(len(data1)):\n",
    "    if row %5000 == 0:\n",
    "        print (\"processing row: \", row)\n",
    "    sentences = data1['cleaned_principal_risks'].iloc[row]\n",
    "    for i in range(len(sentences)):\n",
    "        for word in ph_word:\n",
    "            tokens = sentences[i].lower().split()\n",
    "            if word in tokens:\n",
    "                ph_sents.append([data1['accession#'].iloc[row],\n",
    "                                 data1['filing_year'].iloc[row],\n",
    "                                 data1['fund_name'].iloc[row],\n",
    "                                 sentences[i]])\n",
    "        \n",
    "        \n",
    "        #pubic_health = pubic_health.append({'accession#':data1['accession#'].iloc[row],\n",
    "        #                                    'filing_year':data1['filing_year'].iloc[row],\n",
    "        #                                    'fund_name':data1['fund_name'].iloc[row],                                                    \n",
    "        #                                    'sentences':sentences[i]},ignore_index=True)\n",
    "                                            #'sentences':re.sub(' +', ' ',\" \".join(sentences[i]).replace('\\n',' '))},ignore_index=True)\n",
    "pubic_health = pd.DataFrame(ph_sents, columns =['accession#',\n",
    "                                                'filing_year',\n",
    "                                                'fund_name', \n",
    "                                                'sentences'])               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78b45583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10958, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubic_health.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb75721c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accession#</th>\n",
       "      <th>filing_year</th>\n",
       "      <th>fund_name</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000950123-10-006915</td>\n",
       "      <td>2010</td>\n",
       "      <td>bb&amp;t large cap fund</td>\n",
       "      <td>etf risk: the value of the fundâs investment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001193125-10-044893</td>\n",
       "      <td>2010</td>\n",
       "      <td>aston/new century absolute return etf fund</td>\n",
       "      <td>the value of commodities and commodity contrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001193125-10-045911</td>\n",
       "      <td>2010</td>\n",
       "      <td>aston dynamic allocation fund</td>\n",
       "      <td>the value of commodities and commodity contrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000728889-10-000574</td>\n",
       "      <td>2010</td>\n",
       "      <td>oppenheimer real asset fund</td>\n",
       "      <td>prices of commodities and related contracts ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001193125-10-071718</td>\n",
       "      <td>2010</td>\n",
       "      <td>aston/lake partners lasso alternatives fund</td>\n",
       "      <td>the value of commodities and commodity contrac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             accession# filing_year  \\\n",
       "0  0000950123-10-006915        2010   \n",
       "1  0001193125-10-044893        2010   \n",
       "2  0001193125-10-045911        2010   \n",
       "3  0000728889-10-000574        2010   \n",
       "4  0001193125-10-071718        2010   \n",
       "\n",
       "                                     fund_name  \\\n",
       "0                          bb&t large cap fund   \n",
       "1   aston/new century absolute return etf fund   \n",
       "2                aston dynamic allocation fund   \n",
       "3                  oppenheimer real asset fund   \n",
       "4  aston/lake partners lasso alternatives fund   \n",
       "\n",
       "                                           sentences  \n",
       "0  etf risk: the value of the fundâs investment...  \n",
       "1  the value of commodities and commodity contrac...  \n",
       "2  the value of commodities and commodity contrac...  \n",
       "3  prices of commodities and related contracts ma...  \n",
       "4  the value of commodities and commodity contrac...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubic_health.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69700507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    8912\n",
       "2017     262\n",
       "2016     242\n",
       "2015     231\n",
       "2018     230\n",
       "2019     205\n",
       "2014     173\n",
       "2012     126\n",
       "2013     126\n",
       "2011     110\n",
       "2010      56\n",
       "2021      43\n",
       "Name: filing_year, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubic_health['filing_year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "789d0b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubic_health.to_excel(\"2021_07_public_health_keywords_sentences_dedup_23_01.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb26a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    " nd_word = [ 'cyclones',                   \n",
    "             'death',                      \n",
    "             'drought',                    \n",
    "             'earthquakes',                \n",
    "             'environmental damage',       \n",
    "             'cloud',                      \n",
    "             'disaster',                   \n",
    "             'droughts',                   \n",
    "             'earthquake',                 \n",
    "             'fire',                       \n",
    "             'flood',                      \n",
    "             'hurricane',                  \n",
    "             'hurricanes',                 \n",
    "             'lightning',                  \n",
    "             'natural disaster',           \n",
    "             'natural disasters',          \n",
    "             'seismic',                    \n",
    "             'storms',                     \n",
    "             'tornadoes',                  \n",
    "             'tsunami',                    \n",
    "             'underground',                \n",
    "             'volcanoes',                  \n",
    "             'windstorms']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a6a8ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing row:  0\n",
      "processing row:  5000\n",
      "processing row:  10000\n",
      "processing row:  15000\n",
      "processing row:  20000\n",
      "processing row:  25000\n",
      "processing row:  30000\n",
      "processing row:  35000\n",
      "processing row:  40000\n",
      "processing row:  45000\n",
      "processing row:  50000\n",
      "processing row:  55000\n",
      "processing row:  60000\n",
      "processing row:  65000\n",
      "processing row:  70000\n",
      "processing row:  75000\n",
      "processing row:  80000\n",
      "processing row:  85000\n",
      "processing row:  90000\n",
      "processing row:  95000\n",
      "processing row:  100000\n",
      "processing row:  105000\n",
      "processing row:  110000\n"
     ]
    }
   ],
   "source": [
    "nd_sents = []\n",
    "for row in range(len(data1)):\n",
    "    if row %5000 == 0:\n",
    "        print (\"processing row: \", row)\n",
    "    sentences = data1['cleaned_principal_risks'].iloc[row]\n",
    "    for i in range(len(sentences)):\n",
    "        for word in nd_word:\n",
    "            tokens = sentences[i].lower().split()\n",
    "            if word in tokens:\n",
    "                nd_sents.append([data1['accession#'].iloc[row],\n",
    "                                 data1['filing_year'].iloc[row],\n",
    "                                 data1['fund_name'].iloc[row],\n",
    "                                 sentences[i]])\n",
    "        \n",
    "        \n",
    "        #pubic_health = pubic_health.append({'accession#':data1['accession#'].iloc[row],\n",
    "        #                                    'filing_year':data1['filing_year'].iloc[row],\n",
    "        #                                    'fund_name':data1['fund_name'].iloc[row],                                                    \n",
    "        #                                    'sentences':sentences[i]},ignore_index=True)\n",
    "                                            #'sentences':re.sub(' +', ' ',\" \".join(sentences[i]).replace('\\n',' '))},ignore_index=True)\n",
    "natural_disaster = pd.DataFrame(nd_sents, columns =['accession#',\n",
    "                                                'filing_year',\n",
    "                                                'fund_name', \n",
    "                                                'sentences'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6386c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8866, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natural_disaster.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ba8a43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    2067\n",
       "2019     974\n",
       "2018     962\n",
       "2017     876\n",
       "2016     806\n",
       "2015     762\n",
       "2014     577\n",
       "2013     510\n",
       "2012     449\n",
       "2011     301\n",
       "2010     144\n",
       "2021      13\n",
       "Name: filing_year, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natural_disaster['filing_year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f8a98f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_disaster.to_excel(\"2021_07_natural_disaster_keywords_sentences_dedup_23_01.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1435068",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '2021_07_public_health_keywords_sentences_23_01.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-c9a7157b721e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpubic_health_non_dedup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2021_07_public_health_keywords_sentences_23_01.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1189\u001b[0m                 \u001b[0mext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xls\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m                 ext = inspect_excel_format(\n\u001b[0m\u001b[0;32m   1192\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m                 )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1070\u001b[1;33m     with get_handle(\n\u001b[0m\u001b[0;32m   1071\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m     ) as handle:\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    708\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2021_07_public_health_keywords_sentences_23_01.xlsx'"
     ]
    }
   ],
   "source": [
    "pubic_health_non_dedup = pd.read_excel('2021_07_public_health_keywords_sentences_23_01.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661879ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubic_health_non_dedup.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a5ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubic_health_non_dedup['filing_year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dab286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a1cd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbafdaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82796257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bd2ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79331ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b485525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9d79c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77453e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e947c307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e54a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d6a6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b5000a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc4b55b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c4af06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c99918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c449f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94273239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
